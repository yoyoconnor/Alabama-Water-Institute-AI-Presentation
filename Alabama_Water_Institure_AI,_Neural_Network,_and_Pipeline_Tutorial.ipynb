{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "NOeP5hwqyzNT",
      "metadata": {
        "id": "NOeP5hwqyzNT"
      },
      "source": [
        "# üíß OpenAI API Tutorial for Alabama Water Institute (AWI)\n",
        "Welcome to this beginner-friendly tutorial on using the OpenAI API in Python.\n",
        "\n",
        "In this tutorial, you'll learn how to:\n",
        "- Generate text using GPT-4\n",
        "- Use function calling (structured output)\n",
        "- Generate images with DALL¬∑E\n",
        "- Handle errors safely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LpSGtcI8yzNU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpSGtcI8yzNU",
        "outputId": "f672e418-2815-40e5-b5b3-2abdc360130a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ Install OpenAI SDK (skip if already installed)\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Xmn5BuaDyzNU",
      "metadata": {
        "id": "Xmn5BuaDyzNU"
      },
      "source": [
        "## üîê Set Up Your API Key\n",
        "I recommend saving your key in an environment variable for security."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R6BWycrSyzNU",
      "metadata": {
        "id": "R6BWycrSyzNU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')  # Make sure you've set this on Colab or locally"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wfReT3Z3yzNU",
      "metadata": {
        "id": "wfReT3Z3yzNU"
      },
      "source": [
        "## üß† Generate Text with ChatGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3R_tfJlRyzNU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R_tfJlRyzNU",
        "outputId": "dbf41e5c-95bc-448c-bef1-c4495aec718a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure, the hydrological cycle, also known as the water cycle, is a continuous process in which water changes states and locations around the planet. \n",
            "\n",
            "Here it is in simple terms:\n",
            "\n",
            "1. Evaporation: Water from the oceans, lakes, rivers, and the ground surface turns into water vapor due to the Sun's heat. Plants also contribute to this through a process called transpiration.\n",
            "\n",
            "2. Condensation: The water vapor rises into the air, where it cools down and turns back into a liquid, forming clouds. This is condensation.\n",
            "\n",
            "3. Precipitation: When the cloud particles become too heavy to remain suspended in the cloud, they fall back to the Earth as rain, snow, hail, or sleet. This process is called precipitation.\n",
            "\n",
            "4. Runoff and Infiltration: The water that falls to the Earth either evaporates, becomes part of the ground water (infiltration), or runs off into rivers and streams, which eventually lead back to the oceans and the cycle begins again.\n",
            "\n",
            "Remember that this cycle is nature's way of recycling water, and it's essential for all life on Earth.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize client\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "# Call Chat API\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant for water research.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Explain the hydrological cycle in simple terms.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UD2GML9RyzNV",
      "metadata": {
        "id": "UD2GML9RyzNV"
      },
      "source": [
        "## üì∑ Generate Images with DALL¬∑E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "KxE4DWdZ2jW9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxE4DWdZ2jW9",
        "outputId": "7e83ebc2-f478-4d6c-86c7-881134e65edd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-RsZ0ZCzHPOcYWn1fyTNGCev0/user-AnumEixfTKOOCtRJKTwfv7Ib/img-uJcpwZ2zZUMjGczlXs23xsMG.png?st=2025-05-27T18%3A28%3A48Z&se=2025-05-27T20%3A28%3A48Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=cc612491-d948-4d2e-9821-2683df3719f5&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-27T17%3A06%3A51Z&ske=2025-05-28T17%3A06%3A51Z&sks=b&skv=2024-08-04&sig=7bAn9zHVtP1Sj5j7Q2T3Gb/zS7y4UZSS4p/LAwL%2BRYk%3D\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# Initialize client\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY')) # Use the client object and get API key from userdata\n",
        "\n",
        "# Generate image with a text prompt using DALL¬∑E model\n",
        "response = client.images.generate( # Use client.images.generate\n",
        "    model=\"dall-e-2\",  # DALL¬∑E 2 model\n",
        "    prompt=\"a futuristic water research facility in Alabama\",  # Text prompt\n",
        "    n=1,  # Number of images to generate\n",
        "    size=\"1024x1024\",  # Image size, options: \"256x256\", \"512x512\", \"1024x1024\"\n",
        ")\n",
        "\n",
        "# Extract the image URL from the response\n",
        "image_url = response.data[0].url # Access data and url using dot notation\n",
        "print(\"Generated Image URL:\", image_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A5ml_fn4yzNV",
      "metadata": {
        "id": "A5ml_fn4yzNV"
      },
      "source": [
        "## üîçAnalyze text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uxsgG0AQ5SrZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxsgG0AQ5SrZ",
        "outputId": "ef2ec5df-ebe9-40d5-ecfb-1169ec610b62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: The product was amazing, I absolutely love it!\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: It‚Äôs okay, but it could be better. Not bad, not great.\n",
            "Sentiment: Neutral\n",
            "\n",
            "Review: Terrible experience. The product broke after one day.\n",
            "Sentiment: Negative\n",
            "\n",
            "Review: Best purchase ever! Worth every penny.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The quality was poor, very disappointing.\n",
            "Sentiment: Negative\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sample reviews collection\n",
        "reviews = [\n",
        "    \"The product was amazing, I absolutely love it!\",\n",
        "    \"It‚Äôs okay, but it could be better. Not bad, not great.\",\n",
        "    \"Terrible experience. The product broke after one day.\",\n",
        "    \"Best purchase ever! Worth every penny.\",\n",
        "    \"The quality was poor, very disappointing.\"\n",
        "]\n",
        "\n",
        "# Function to analyze sentiment using ChatGPT\n",
        "def analyze_sentiment(reviews):\n",
        "    sentiments = []\n",
        "    for review in reviews:\n",
        "        response = client.chat.completions.create( # Use client.chat.completions.create\n",
        "            model=\"gpt-4\",  # Use GPT-4 for the most accurate results\n",
        "            messages=[ # Use the messages parameter for chat models\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant for sentiment analysis. Respond only with 'Positive', 'Neutral', or 'Negative'.\"}, # Add a system message to guide the model\n",
        "                {\"role\": \"user\", \"content\": f\"Analyze the sentiment of the following review: '{review}'.\"} # Format the user message\n",
        "            ],\n",
        "            max_tokens=10,  # Only need the sentiment, so a short response\n",
        "            temperature=0.0,  # Set temperature to 0 for a more deterministic answer\n",
        "        )\n",
        "        sentiment = response.choices[0].message.content.strip() # Access content using .message.content\n",
        "        sentiments.append(sentiment)\n",
        "    return sentiments\n",
        "\n",
        "# Get sentiment for each review\n",
        "sentiments = analyze_sentiment(reviews)\n",
        "\n",
        "# Print out the results\n",
        "for review, sentiment in zip(reviews, sentiments):\n",
        "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e188937",
      "metadata": {
        "id": "7e188937"
      },
      "source": [
        "## üöß Handle Errors Safely\n",
        "\n",
        "When working with external APIs like OpenAI, it's crucial to handle potential errors gracefully. Common errors include network issues, invalid API keys, rate limits, and model-specific errors. You can use `try...except` blocks to catch these errors and provide informative feedback or retry mechanisms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e190ea9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e190ea9",
        "outputId": "76f60cb3-8384-494c-9ba9-c36d55a381e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Safe API Call Response:\n",
            "Alright, let's take the concept of Quantum Mechanics, which is one of the pillars of modern physics, and simplify it as much as possible. This is going to be a long ride so buckle up!\n",
            "\n",
            "Quantum Mechanics, at its core, is a physical science dealing with the behavior of matter and light at the molecular, atomic, nuclear, and even smaller, microscopic levels. \n",
            "\n",
            "1. **Wave-Particle Duality**: To start with, one of the most mind-bending theories in quantum\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI, APIError, RateLimitError\n",
        "from google.colab import userdata\n",
        "import time\n",
        "\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "def safe_chat_completion(prompt, model=\"gpt-4\", max_tokens=100, temperature=0.7, retries=3):\n",
        "    \"\"\"\n",
        "    Safely call the chat completion API with retry logic.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=messages,\n",
        "                max_tokens=max_tokens,\n",
        "                temperature=temperature,\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "\n",
        "        except RateLimitError:\n",
        "            wait_time = (2 ** attempt) # Exponential backoff\n",
        "            print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
        "            time.sleep(wait_time)\n",
        "        except APIError as e:\n",
        "            print(f\"API Error: {e}\")\n",
        "            break # Don't retry for other API errors\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")\n",
        "            break # Don't retry for unexpected errors\n",
        "\n",
        "    return \"Failed to get a response after multiple retries.\"\n",
        "\n",
        "# Example usage with a potentially problematic prompt (e.g., very long or complex)\n",
        "# You can replace this with a prompt that might cause an error to test the handling\n",
        "test_prompt = \"Explain a complex scientific concept in simple terms, making it very long and detailed.\"\n",
        "response = safe_chat_completion(test_prompt)\n",
        "print(\"\\nSafe API Call Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "buvYtKV47ZsH",
      "metadata": {
        "id": "buvYtKV47ZsH"
      },
      "source": [
        "# üî• PyTorch For Neural Networks Tutorial for the Alabama Water Insitute (AWI)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lxS_1MP_chOI",
      "metadata": {
        "id": "lxS_1MP_chOI"
      },
      "source": [
        "##1. Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0mpDruw1c3e2",
      "metadata": {
        "id": "0mpDruw1c3e2"
      },
      "source": [
        "Overview of PyTorch\n",
        "PyTorch is an open-source deep learning library for applications like computer vision and NLP. It‚Äôs known for its flexibility, ease of use, and support for GPU acceleration.\n",
        "\n",
        "\n",
        "Why PyTorch for Neural Networks?\n",
        "Dynamic Computation Graph: Flexible network design during training.\n",
        "\n",
        "\n",
        "GPU Support: Speeds up training with hardware acceleration.\n",
        "\n",
        "\n",
        "Neural Networks in Water Research\n",
        "Neural networks are used for:\n",
        "\n",
        "\n",
        "Predicting Water Quality: Forecasting future water conditions.\n",
        "\n",
        "\n",
        "Modeling Environmental Changes: Analyzing trends in water data.\n",
        "\n",
        "\n",
        "Optimizing Water Distribution: Forecasting demand to improve efficiency.\n",
        "\n",
        "\n",
        "Goal of the Tutorial\n",
        "This tutorial covers building, training, and evaluating a neural network in PyTorch, with potential applications to water-related problems.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QqjYKhC3c_3C",
      "metadata": {
        "id": "QqjYKhC3c_3C"
      },
      "source": [
        "##2. Set Up and Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2meEJTwSdFVk",
      "metadata": {
        "id": "2meEJTwSdFVk"
      },
      "source": [
        "- Install Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZpLTDzU4dE4Z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpLTDzU4dE4Z",
        "outputId": "4b0e8ac6-1549-4305-aef5-1a8b34287a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lRKh9K0BdpDh",
      "metadata": {
        "id": "lRKh9K0BdpDh"
      },
      "source": [
        "- Import Necessary Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Djf2n5Q8eIwo",
      "metadata": {
        "id": "Djf2n5Q8eIwo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N1-L_M7NeNe9",
      "metadata": {
        "id": "N1-L_M7NeNe9"
      },
      "source": [
        "##3. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ozCJJfFJeSYg",
      "metadata": {
        "id": "ozCJJfFJeSYg"
      },
      "source": [
        "- Dataset Example: If you have water-related datasets, use that. If not, you could use a sample dataset, like the Iris dataset.\n",
        "\n",
        "- Preprocessing:\n",
        "\n",
        " - Loading data into PyTorch tensors.\n",
        "\n",
        " - Normalizing data if necessary.\n",
        "\n",
        "- Example code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_GyBrh2ueR8E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GyBrh2ueR8E",
        "outputId": "ca1bd76f-b15b-4b92-8b49-d6c2003eba58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input size: 10\n",
            "Output size: 1\n"
          ]
        }
      ],
      "source": [
        "# Example dataset\n",
        "# Replace with actual data\n",
        "data = torch.randn(100, 10)  # Example: 100 samples, 10 features\n",
        "targets = torch.randn(100, 1)  # Example: 100 samples, 1 target\n",
        "\n",
        "input_size = data.shape[1]\n",
        "output_size = targets.shape[1]\n",
        "\n",
        "dataset = TensorDataset(data, targets)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "print(f\"Input size: {input_size}\")\n",
        "print(f\"Output size: {output_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zY2LrI9LenwO",
      "metadata": {
        "id": "zY2LrI9LenwO"
      },
      "source": [
        "##4. Building a Simple Neural Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lRQr-zQOeqw6",
      "metadata": {
        "id": "lRQr-zQOeqw6"
      },
      "source": [
        "- Define the Model: Use `torch.nn.Module` to define a simple fully connected neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lBSpUpRoexpS",
      "metadata": {
        "id": "lBSpUpRoexpS"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)  # Dynamically set input features\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, output_size)  # Dynamically set output features\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K-EYriH2e0Tl",
      "metadata": {
        "id": "K-EYriH2e0Tl"
      },
      "source": [
        "##5. Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5D6_uTSPe47d",
      "metadata": {
        "id": "5D6_uTSPe47d"
      },
      "source": [
        "- Define the Loss Function and Optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0EmmmDrCe7U0",
      "metadata": {
        "id": "0EmmmDrCe7U0"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork(input_size, output_size)\n",
        "criterion = nn.MSELoss()  # Mean Squared Error for regression tasks\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ouhRUOe97_",
      "metadata": {
        "id": "36ouhRUOe97_"
      },
      "source": [
        "- Training Loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G-9hfthPfHhi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-9hfthPfHhi",
        "outputId": "d17a51b8-7b78-4e64-9d03-7b5edd8bd80e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/500], Loss: 0.0000\n",
            "Epoch [2/500], Loss: 0.0009\n",
            "Epoch [3/500], Loss: 0.0006\n",
            "Epoch [4/500], Loss: 0.0000\n",
            "Epoch [5/500], Loss: 0.0009\n",
            "Epoch [6/500], Loss: 0.0015\n",
            "Epoch [7/500], Loss: 0.0002\n",
            "Epoch [8/500], Loss: 0.0010\n",
            "Epoch [9/500], Loss: 0.0018\n",
            "Epoch [10/500], Loss: 0.0000\n",
            "Epoch [11/500], Loss: 0.0001\n",
            "Epoch [12/500], Loss: 0.0008\n",
            "Epoch [13/500], Loss: 0.0006\n",
            "Epoch [14/500], Loss: 0.0002\n",
            "Epoch [15/500], Loss: 0.0010\n",
            "Epoch [16/500], Loss: 0.0004\n",
            "Epoch [17/500], Loss: 0.0016\n",
            "Epoch [18/500], Loss: 0.0001\n",
            "Epoch [19/500], Loss: 0.0002\n",
            "Epoch [20/500], Loss: 0.0010\n",
            "Epoch [21/500], Loss: 0.0002\n",
            "Epoch [22/500], Loss: 0.0001\n",
            "Epoch [23/500], Loss: 0.0003\n",
            "Epoch [24/500], Loss: 0.0007\n",
            "Epoch [25/500], Loss: 0.0002\n",
            "Epoch [26/500], Loss: 0.0003\n",
            "Epoch [27/500], Loss: 0.0015\n",
            "Epoch [28/500], Loss: 0.0019\n",
            "Epoch [29/500], Loss: 0.0003\n",
            "Epoch [30/500], Loss: 0.0006\n",
            "Epoch [31/500], Loss: 0.0005\n",
            "Epoch [32/500], Loss: 0.0002\n",
            "Epoch [33/500], Loss: 0.0007\n",
            "Epoch [34/500], Loss: 0.0002\n",
            "Epoch [35/500], Loss: 0.0003\n",
            "Epoch [36/500], Loss: 0.0007\n",
            "Epoch [37/500], Loss: 0.0002\n",
            "Epoch [38/500], Loss: 0.0013\n",
            "Epoch [39/500], Loss: 0.0019\n",
            "Epoch [40/500], Loss: 0.0006\n",
            "Epoch [41/500], Loss: 0.0006\n",
            "Epoch [42/500], Loss: 0.0004\n",
            "Epoch [43/500], Loss: 0.0010\n",
            "Epoch [44/500], Loss: 0.0020\n",
            "Epoch [45/500], Loss: 0.0012\n",
            "Epoch [46/500], Loss: 0.0008\n",
            "Epoch [47/500], Loss: 0.0009\n",
            "Epoch [48/500], Loss: 0.0015\n",
            "Epoch [49/500], Loss: 0.0011\n",
            "Epoch [50/500], Loss: 0.0008\n",
            "Epoch [51/500], Loss: 0.0006\n",
            "Epoch [52/500], Loss: 0.0005\n",
            "Epoch [53/500], Loss: 0.0004\n",
            "Epoch [54/500], Loss: 0.0018\n",
            "Epoch [55/500], Loss: 0.0009\n",
            "Epoch [56/500], Loss: 0.0024\n",
            "Epoch [57/500], Loss: 0.0004\n",
            "Epoch [58/500], Loss: 0.0002\n",
            "Epoch [59/500], Loss: 0.0003\n",
            "Epoch [60/500], Loss: 0.0031\n",
            "Epoch [61/500], Loss: 0.0007\n",
            "Epoch [62/500], Loss: 0.0016\n",
            "Epoch [63/500], Loss: 0.0054\n",
            "Epoch [64/500], Loss: 0.0035\n",
            "Epoch [65/500], Loss: 0.0006\n",
            "Epoch [66/500], Loss: 0.0248\n",
            "Epoch [67/500], Loss: 0.0085\n",
            "Epoch [68/500], Loss: 0.0035\n",
            "Epoch [69/500], Loss: 0.0032\n",
            "Epoch [70/500], Loss: 0.0228\n",
            "Epoch [71/500], Loss: 0.0023\n",
            "Epoch [72/500], Loss: 0.0214\n",
            "Epoch [73/500], Loss: 0.0021\n",
            "Epoch [74/500], Loss: 0.0103\n",
            "Epoch [75/500], Loss: 0.0077\n",
            "Epoch [76/500], Loss: 0.0022\n",
            "Epoch [77/500], Loss: 0.0014\n",
            "Epoch [78/500], Loss: 0.0080\n",
            "Epoch [79/500], Loss: 0.0062\n",
            "Epoch [80/500], Loss: 0.0169\n",
            "Epoch [81/500], Loss: 0.0034\n",
            "Epoch [82/500], Loss: 0.0065\n",
            "Epoch [83/500], Loss: 0.0169\n",
            "Epoch [84/500], Loss: 0.0040\n",
            "Epoch [85/500], Loss: 0.0035\n",
            "Epoch [86/500], Loss: 0.0007\n",
            "Epoch [87/500], Loss: 0.0030\n",
            "Epoch [88/500], Loss: 0.0006\n",
            "Epoch [89/500], Loss: 0.0082\n",
            "Epoch [90/500], Loss: 0.0395\n",
            "Epoch [91/500], Loss: 0.0093\n",
            "Epoch [92/500], Loss: 0.0198\n",
            "Epoch [93/500], Loss: 0.0139\n",
            "Epoch [94/500], Loss: 0.0090\n",
            "Epoch [95/500], Loss: 0.0061\n",
            "Epoch [96/500], Loss: 0.0032\n",
            "Epoch [97/500], Loss: 0.0018\n",
            "Epoch [98/500], Loss: 0.0156\n",
            "Epoch [99/500], Loss: 0.0005\n",
            "Epoch [100/500], Loss: 0.0012\n",
            "Epoch [101/500], Loss: 0.0032\n",
            "Epoch [102/500], Loss: 0.0052\n",
            "Epoch [103/500], Loss: 0.0030\n",
            "Epoch [104/500], Loss: 0.0040\n",
            "Epoch [105/500], Loss: 0.0015\n",
            "Epoch [106/500], Loss: 0.0013\n",
            "Epoch [107/500], Loss: 0.0034\n",
            "Epoch [108/500], Loss: 0.0009\n",
            "Epoch [109/500], Loss: 0.0001\n",
            "Epoch [110/500], Loss: 0.0013\n",
            "Epoch [111/500], Loss: 0.0007\n",
            "Epoch [112/500], Loss: 0.0002\n",
            "Epoch [113/500], Loss: 0.0010\n",
            "Epoch [114/500], Loss: 0.0010\n",
            "Epoch [115/500], Loss: 0.0005\n",
            "Epoch [116/500], Loss: 0.0008\n",
            "Epoch [117/500], Loss: 0.0005\n",
            "Epoch [118/500], Loss: 0.0001\n",
            "Epoch [119/500], Loss: 0.0004\n",
            "Epoch [120/500], Loss: 0.0002\n",
            "Epoch [121/500], Loss: 0.0002\n",
            "Epoch [122/500], Loss: 0.0001\n",
            "Epoch [123/500], Loss: 0.0000\n",
            "Epoch [124/500], Loss: 0.0001\n",
            "Epoch [125/500], Loss: 0.0001\n",
            "Epoch [126/500], Loss: 0.0000\n",
            "Epoch [127/500], Loss: 0.0001\n",
            "Epoch [128/500], Loss: 0.0001\n",
            "Epoch [129/500], Loss: 0.0001\n",
            "Epoch [130/500], Loss: 0.0000\n",
            "Epoch [131/500], Loss: 0.0000\n",
            "Epoch [132/500], Loss: 0.0000\n",
            "Epoch [133/500], Loss: 0.0000\n",
            "Epoch [134/500], Loss: 0.0000\n",
            "Epoch [135/500], Loss: 0.0000\n",
            "Epoch [136/500], Loss: 0.0000\n",
            "Epoch [137/500], Loss: 0.0000\n",
            "Epoch [138/500], Loss: 0.0000\n",
            "Epoch [139/500], Loss: 0.0000\n",
            "Epoch [140/500], Loss: 0.0000\n",
            "Epoch [141/500], Loss: 0.0000\n",
            "Epoch [142/500], Loss: 0.0000\n",
            "Epoch [143/500], Loss: 0.0000\n",
            "Epoch [144/500], Loss: 0.0000\n",
            "Epoch [145/500], Loss: 0.0000\n",
            "Epoch [146/500], Loss: 0.0000\n",
            "Epoch [147/500], Loss: 0.0000\n",
            "Epoch [148/500], Loss: 0.0000\n",
            "Epoch [149/500], Loss: 0.0000\n",
            "Epoch [150/500], Loss: 0.0000\n",
            "Epoch [151/500], Loss: 0.0000\n",
            "Epoch [152/500], Loss: 0.0000\n",
            "Epoch [153/500], Loss: 0.0000\n",
            "Epoch [154/500], Loss: 0.0000\n",
            "Epoch [155/500], Loss: 0.0000\n",
            "Epoch [156/500], Loss: 0.0000\n",
            "Epoch [157/500], Loss: 0.0000\n",
            "Epoch [158/500], Loss: 0.0000\n",
            "Epoch [159/500], Loss: 0.0000\n",
            "Epoch [160/500], Loss: 0.0000\n",
            "Epoch [161/500], Loss: 0.0000\n",
            "Epoch [162/500], Loss: 0.0000\n",
            "Epoch [163/500], Loss: 0.0000\n",
            "Epoch [164/500], Loss: 0.0000\n",
            "Epoch [165/500], Loss: 0.0000\n",
            "Epoch [166/500], Loss: 0.0000\n",
            "Epoch [167/500], Loss: 0.0000\n",
            "Epoch [168/500], Loss: 0.0000\n",
            "Epoch [169/500], Loss: 0.0000\n",
            "Epoch [170/500], Loss: 0.0000\n",
            "Epoch [171/500], Loss: 0.0000\n",
            "Epoch [172/500], Loss: 0.0000\n",
            "Epoch [173/500], Loss: 0.0000\n",
            "Epoch [174/500], Loss: 0.0000\n",
            "Epoch [175/500], Loss: 0.0000\n",
            "Epoch [176/500], Loss: 0.0000\n",
            "Epoch [177/500], Loss: 0.0000\n",
            "Epoch [178/500], Loss: 0.0000\n",
            "Epoch [179/500], Loss: 0.0000\n",
            "Epoch [180/500], Loss: 0.0000\n",
            "Epoch [181/500], Loss: 0.0000\n",
            "Epoch [182/500], Loss: 0.0000\n",
            "Epoch [183/500], Loss: 0.0000\n",
            "Epoch [184/500], Loss: 0.0000\n",
            "Epoch [185/500], Loss: 0.0000\n",
            "Epoch [186/500], Loss: 0.0000\n",
            "Epoch [187/500], Loss: 0.0000\n",
            "Epoch [188/500], Loss: 0.0000\n",
            "Epoch [189/500], Loss: 0.0000\n",
            "Epoch [190/500], Loss: 0.0000\n",
            "Epoch [191/500], Loss: 0.0000\n",
            "Epoch [192/500], Loss: 0.0000\n",
            "Epoch [193/500], Loss: 0.0000\n",
            "Epoch [194/500], Loss: 0.0000\n",
            "Epoch [195/500], Loss: 0.0000\n",
            "Epoch [196/500], Loss: 0.0000\n",
            "Epoch [197/500], Loss: 0.0000\n",
            "Epoch [198/500], Loss: 0.0000\n",
            "Epoch [199/500], Loss: 0.0000\n",
            "Epoch [200/500], Loss: 0.0000\n",
            "Epoch [201/500], Loss: 0.0000\n",
            "Epoch [202/500], Loss: 0.0000\n",
            "Epoch [203/500], Loss: 0.0000\n",
            "Epoch [204/500], Loss: 0.0000\n",
            "Epoch [205/500], Loss: 0.0000\n",
            "Epoch [206/500], Loss: 0.0000\n",
            "Epoch [207/500], Loss: 0.0000\n",
            "Epoch [208/500], Loss: 0.0000\n",
            "Epoch [209/500], Loss: 0.0000\n",
            "Epoch [210/500], Loss: 0.0000\n",
            "Epoch [211/500], Loss: 0.0000\n",
            "Epoch [212/500], Loss: 0.0000\n",
            "Epoch [213/500], Loss: 0.0000\n",
            "Epoch [214/500], Loss: 0.0000\n",
            "Epoch [215/500], Loss: 0.0000\n",
            "Epoch [216/500], Loss: 0.0000\n",
            "Epoch [217/500], Loss: 0.0000\n",
            "Epoch [218/500], Loss: 0.0000\n",
            "Epoch [219/500], Loss: 0.0000\n",
            "Epoch [220/500], Loss: 0.0000\n",
            "Epoch [221/500], Loss: 0.0000\n",
            "Epoch [222/500], Loss: 0.0000\n",
            "Epoch [223/500], Loss: 0.0000\n",
            "Epoch [224/500], Loss: 0.0000\n",
            "Epoch [225/500], Loss: 0.0000\n",
            "Epoch [226/500], Loss: 0.0000\n",
            "Epoch [227/500], Loss: 0.0000\n",
            "Epoch [228/500], Loss: 0.0000\n",
            "Epoch [229/500], Loss: 0.0000\n",
            "Epoch [230/500], Loss: 0.0000\n",
            "Epoch [231/500], Loss: 0.0000\n",
            "Epoch [232/500], Loss: 0.0000\n",
            "Epoch [233/500], Loss: 0.0000\n",
            "Epoch [234/500], Loss: 0.0000\n",
            "Epoch [235/500], Loss: 0.0000\n",
            "Epoch [236/500], Loss: 0.0000\n",
            "Epoch [237/500], Loss: 0.0000\n",
            "Epoch [238/500], Loss: 0.0001\n",
            "Epoch [239/500], Loss: 0.0000\n",
            "Epoch [240/500], Loss: 0.0000\n",
            "Epoch [241/500], Loss: 0.0001\n",
            "Epoch [242/500], Loss: 0.0000\n",
            "Epoch [243/500], Loss: 0.0001\n",
            "Epoch [244/500], Loss: 0.0000\n",
            "Epoch [245/500], Loss: 0.0000\n",
            "Epoch [246/500], Loss: 0.0001\n",
            "Epoch [247/500], Loss: 0.0000\n",
            "Epoch [248/500], Loss: 0.0001\n",
            "Epoch [249/500], Loss: 0.0001\n",
            "Epoch [250/500], Loss: 0.0000\n",
            "Epoch [251/500], Loss: 0.0004\n",
            "Epoch [252/500], Loss: 0.0000\n",
            "Epoch [253/500], Loss: 0.0002\n",
            "Epoch [254/500], Loss: 0.0000\n",
            "Epoch [255/500], Loss: 0.0004\n",
            "Epoch [256/500], Loss: 0.0005\n",
            "Epoch [257/500], Loss: 0.0001\n",
            "Epoch [258/500], Loss: 0.0008\n",
            "Epoch [259/500], Loss: 0.0007\n",
            "Epoch [260/500], Loss: 0.0004\n",
            "Epoch [261/500], Loss: 0.0003\n",
            "Epoch [262/500], Loss: 0.0000\n",
            "Epoch [263/500], Loss: 0.0004\n",
            "Epoch [264/500], Loss: 0.0009\n",
            "Epoch [265/500], Loss: 0.0002\n",
            "Epoch [266/500], Loss: 0.0006\n",
            "Epoch [267/500], Loss: 0.0001\n",
            "Epoch [268/500], Loss: 0.0010\n",
            "Epoch [269/500], Loss: 0.0025\n",
            "Epoch [270/500], Loss: 0.0015\n",
            "Epoch [271/500], Loss: 0.0021\n",
            "Epoch [272/500], Loss: 0.0009\n",
            "Epoch [273/500], Loss: 0.0009\n",
            "Epoch [274/500], Loss: 0.0012\n",
            "Epoch [275/500], Loss: 0.0020\n",
            "Epoch [276/500], Loss: 0.0006\n",
            "Epoch [277/500], Loss: 0.0018\n",
            "Epoch [278/500], Loss: 0.0006\n",
            "Epoch [279/500], Loss: 0.0004\n",
            "Epoch [280/500], Loss: 0.0009\n",
            "Epoch [281/500], Loss: 0.0002\n",
            "Epoch [282/500], Loss: 0.0005\n",
            "Epoch [283/500], Loss: 0.0004\n",
            "Epoch [284/500], Loss: 0.0002\n",
            "Epoch [285/500], Loss: 0.0005\n",
            "Epoch [286/500], Loss: 0.0005\n",
            "Epoch [287/500], Loss: 0.0003\n",
            "Epoch [288/500], Loss: 0.0017\n",
            "Epoch [289/500], Loss: 0.0009\n",
            "Epoch [290/500], Loss: 0.0004\n",
            "Epoch [291/500], Loss: 0.0012\n",
            "Epoch [292/500], Loss: 0.0045\n",
            "Epoch [293/500], Loss: 0.0022\n",
            "Epoch [294/500], Loss: 0.0026\n",
            "Epoch [295/500], Loss: 0.0026\n",
            "Epoch [296/500], Loss: 0.0013\n",
            "Epoch [297/500], Loss: 0.0018\n",
            "Epoch [298/500], Loss: 0.0028\n",
            "Epoch [299/500], Loss: 0.0013\n",
            "Epoch [300/500], Loss: 0.0043\n",
            "Epoch [301/500], Loss: 0.0014\n",
            "Epoch [302/500], Loss: 0.0007\n",
            "Epoch [303/500], Loss: 0.0005\n",
            "Epoch [304/500], Loss: 0.0013\n",
            "Epoch [305/500], Loss: 0.0008\n",
            "Epoch [306/500], Loss: 0.0004\n",
            "Epoch [307/500], Loss: 0.0006\n",
            "Epoch [308/500], Loss: 0.0014\n",
            "Epoch [309/500], Loss: 0.0010\n",
            "Epoch [310/500], Loss: 0.0004\n",
            "Epoch [311/500], Loss: 0.0004\n",
            "Epoch [312/500], Loss: 0.0004\n",
            "Epoch [313/500], Loss: 0.0007\n",
            "Epoch [314/500], Loss: 0.0004\n",
            "Epoch [315/500], Loss: 0.0001\n",
            "Epoch [316/500], Loss: 0.0002\n",
            "Epoch [317/500], Loss: 0.0003\n",
            "Epoch [318/500], Loss: 0.0003\n",
            "Epoch [319/500], Loss: 0.0003\n",
            "Epoch [320/500], Loss: 0.0003\n",
            "Epoch [321/500], Loss: 0.0002\n",
            "Epoch [322/500], Loss: 0.0002\n",
            "Epoch [323/500], Loss: 0.0003\n",
            "Epoch [324/500], Loss: 0.0002\n",
            "Epoch [325/500], Loss: 0.0003\n",
            "Epoch [326/500], Loss: 0.0000\n",
            "Epoch [327/500], Loss: 0.0001\n",
            "Epoch [328/500], Loss: 0.0001\n",
            "Epoch [329/500], Loss: 0.0006\n",
            "Epoch [330/500], Loss: 0.0001\n",
            "Epoch [331/500], Loss: 0.0001\n",
            "Epoch [332/500], Loss: 0.0004\n",
            "Epoch [333/500], Loss: 0.0001\n",
            "Epoch [334/500], Loss: 0.0000\n",
            "Epoch [335/500], Loss: 0.0001\n",
            "Epoch [336/500], Loss: 0.0006\n",
            "Epoch [337/500], Loss: 0.0002\n",
            "Epoch [338/500], Loss: 0.0005\n",
            "Epoch [339/500], Loss: 0.0001\n",
            "Epoch [340/500], Loss: 0.0002\n",
            "Epoch [341/500], Loss: 0.0003\n",
            "Epoch [342/500], Loss: 0.0004\n",
            "Epoch [343/500], Loss: 0.0001\n",
            "Epoch [344/500], Loss: 0.0001\n",
            "Epoch [345/500], Loss: 0.0001\n",
            "Epoch [346/500], Loss: 0.0001\n",
            "Epoch [347/500], Loss: 0.0002\n",
            "Epoch [348/500], Loss: 0.0005\n",
            "Epoch [349/500], Loss: 0.0000\n",
            "Epoch [350/500], Loss: 0.0005\n",
            "Epoch [351/500], Loss: 0.0002\n",
            "Epoch [352/500], Loss: 0.0002\n",
            "Epoch [353/500], Loss: 0.0001\n",
            "Epoch [354/500], Loss: 0.0002\n",
            "Epoch [355/500], Loss: 0.0000\n",
            "Epoch [356/500], Loss: 0.0001\n",
            "Epoch [357/500], Loss: 0.0002\n",
            "Epoch [358/500], Loss: 0.0001\n",
            "Epoch [359/500], Loss: 0.0001\n",
            "Epoch [360/500], Loss: 0.0002\n",
            "Epoch [361/500], Loss: 0.0001\n",
            "Epoch [362/500], Loss: 0.0003\n",
            "Epoch [363/500], Loss: 0.0002\n",
            "Epoch [364/500], Loss: 0.0001\n",
            "Epoch [365/500], Loss: 0.0008\n",
            "Epoch [366/500], Loss: 0.0004\n",
            "Epoch [367/500], Loss: 0.0002\n",
            "Epoch [368/500], Loss: 0.0003\n",
            "Epoch [369/500], Loss: 0.0001\n",
            "Epoch [370/500], Loss: 0.0002\n",
            "Epoch [371/500], Loss: 0.0003\n",
            "Epoch [372/500], Loss: 0.0005\n",
            "Epoch [373/500], Loss: 0.0012\n",
            "Epoch [374/500], Loss: 0.0014\n",
            "Epoch [375/500], Loss: 0.0035\n",
            "Epoch [376/500], Loss: 0.0015\n",
            "Epoch [377/500], Loss: 0.0047\n",
            "Epoch [378/500], Loss: 0.0039\n",
            "Epoch [379/500], Loss: 0.0011\n",
            "Epoch [380/500], Loss: 0.0010\n",
            "Epoch [381/500], Loss: 0.0138\n",
            "Epoch [382/500], Loss: 0.0008\n",
            "Epoch [383/500], Loss: 0.0014\n",
            "Epoch [384/500], Loss: 0.0001\n",
            "Epoch [385/500], Loss: 0.0006\n",
            "Epoch [386/500], Loss: 0.0018\n",
            "Epoch [387/500], Loss: 0.0004\n",
            "Epoch [388/500], Loss: 0.0012\n",
            "Epoch [389/500], Loss: 0.0008\n",
            "Epoch [390/500], Loss: 0.0005\n",
            "Epoch [391/500], Loss: 0.0019\n",
            "Epoch [392/500], Loss: 0.0007\n",
            "Epoch [393/500], Loss: 0.0015\n",
            "Epoch [394/500], Loss: 0.0012\n",
            "Epoch [395/500], Loss: 0.0018\n",
            "Epoch [396/500], Loss: 0.0043\n",
            "Epoch [397/500], Loss: 0.0026\n",
            "Epoch [398/500], Loss: 0.0018\n",
            "Epoch [399/500], Loss: 0.0034\n",
            "Epoch [400/500], Loss: 0.0065\n",
            "Epoch [401/500], Loss: 0.0044\n",
            "Epoch [402/500], Loss: 0.0082\n",
            "Epoch [403/500], Loss: 0.0186\n",
            "Epoch [404/500], Loss: 0.0130\n",
            "Epoch [405/500], Loss: 0.0089\n",
            "Epoch [406/500], Loss: 0.0102\n",
            "Epoch [407/500], Loss: 0.0100\n",
            "Epoch [408/500], Loss: 0.0046\n",
            "Epoch [409/500], Loss: 0.0032\n",
            "Epoch [410/500], Loss: 0.0073\n",
            "Epoch [411/500], Loss: 0.0220\n",
            "Epoch [412/500], Loss: 0.0122\n",
            "Epoch [413/500], Loss: 0.0079\n",
            "Epoch [414/500], Loss: 0.0407\n",
            "Epoch [415/500], Loss: 0.0237\n",
            "Epoch [416/500], Loss: 0.0210\n",
            "Epoch [417/500], Loss: 0.0301\n",
            "Epoch [418/500], Loss: 0.0210\n",
            "Epoch [419/500], Loss: 0.0285\n",
            "Epoch [420/500], Loss: 0.0190\n",
            "Epoch [421/500], Loss: 0.0117\n",
            "Epoch [422/500], Loss: 0.0033\n",
            "Epoch [423/500], Loss: 0.0057\n",
            "Epoch [424/500], Loss: 0.0042\n",
            "Epoch [425/500], Loss: 0.0007\n",
            "Epoch [426/500], Loss: 0.0043\n",
            "Epoch [427/500], Loss: 0.0032\n",
            "Epoch [428/500], Loss: 0.0031\n",
            "Epoch [429/500], Loss: 0.0008\n",
            "Epoch [430/500], Loss: 0.0002\n",
            "Epoch [431/500], Loss: 0.0003\n",
            "Epoch [432/500], Loss: 0.0001\n",
            "Epoch [433/500], Loss: 0.0004\n",
            "Epoch [434/500], Loss: 0.0003\n",
            "Epoch [435/500], Loss: 0.0004\n",
            "Epoch [436/500], Loss: 0.0002\n",
            "Epoch [437/500], Loss: 0.0002\n",
            "Epoch [438/500], Loss: 0.0001\n",
            "Epoch [439/500], Loss: 0.0001\n",
            "Epoch [440/500], Loss: 0.0005\n",
            "Epoch [441/500], Loss: 0.0001\n",
            "Epoch [442/500], Loss: 0.0003\n",
            "Epoch [443/500], Loss: 0.0006\n",
            "Epoch [444/500], Loss: 0.0002\n",
            "Epoch [445/500], Loss: 0.0001\n",
            "Epoch [446/500], Loss: 0.0002\n",
            "Epoch [447/500], Loss: 0.0001\n",
            "Epoch [448/500], Loss: 0.0001\n",
            "Epoch [449/500], Loss: 0.0001\n",
            "Epoch [450/500], Loss: 0.0001\n",
            "Epoch [451/500], Loss: 0.0002\n",
            "Epoch [452/500], Loss: 0.0001\n",
            "Epoch [453/500], Loss: 0.0000\n",
            "Epoch [454/500], Loss: 0.0001\n",
            "Epoch [455/500], Loss: 0.0000\n",
            "Epoch [456/500], Loss: 0.0000\n",
            "Epoch [457/500], Loss: 0.0000\n",
            "Epoch [458/500], Loss: 0.0000\n",
            "Epoch [459/500], Loss: 0.0001\n",
            "Epoch [460/500], Loss: 0.0000\n",
            "Epoch [461/500], Loss: 0.0000\n",
            "Epoch [462/500], Loss: 0.0000\n",
            "Epoch [463/500], Loss: 0.0000\n",
            "Epoch [464/500], Loss: 0.0000\n",
            "Epoch [465/500], Loss: 0.0000\n",
            "Epoch [466/500], Loss: 0.0000\n",
            "Epoch [467/500], Loss: 0.0000\n",
            "Epoch [468/500], Loss: 0.0000\n",
            "Epoch [469/500], Loss: 0.0000\n",
            "Epoch [470/500], Loss: 0.0000\n",
            "Epoch [471/500], Loss: 0.0000\n",
            "Epoch [472/500], Loss: 0.0000\n",
            "Epoch [473/500], Loss: 0.0000\n",
            "Epoch [474/500], Loss: 0.0000\n",
            "Epoch [475/500], Loss: 0.0000\n",
            "Epoch [476/500], Loss: 0.0000\n",
            "Epoch [477/500], Loss: 0.0000\n",
            "Epoch [478/500], Loss: 0.0000\n",
            "Epoch [479/500], Loss: 0.0000\n",
            "Epoch [480/500], Loss: 0.0000\n",
            "Epoch [481/500], Loss: 0.0000\n",
            "Epoch [482/500], Loss: 0.0000\n",
            "Epoch [483/500], Loss: 0.0000\n",
            "Epoch [484/500], Loss: 0.0000\n",
            "Epoch [485/500], Loss: 0.0000\n",
            "Epoch [486/500], Loss: 0.0000\n",
            "Epoch [487/500], Loss: 0.0000\n",
            "Epoch [488/500], Loss: 0.0000\n",
            "Epoch [489/500], Loss: 0.0000\n",
            "Epoch [490/500], Loss: 0.0000\n",
            "Epoch [491/500], Loss: 0.0000\n",
            "Epoch [492/500], Loss: 0.0000\n",
            "Epoch [493/500], Loss: 0.0000\n",
            "Epoch [494/500], Loss: 0.0000\n",
            "Epoch [495/500], Loss: 0.0000\n",
            "Epoch [496/500], Loss: 0.0000\n",
            "Epoch [497/500], Loss: 0.0000\n",
            "Epoch [498/500], Loss: 0.0000\n",
            "Epoch [499/500], Loss: 0.0000\n",
            "Epoch [500/500], Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    for batch_data, batch_targets in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_data)\n",
        "        loss = criterion(outputs, batch_targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n5gaq4yifIZQ",
      "metadata": {
        "id": "n5gaq4yifIZQ"
      },
      "source": [
        "##6. Evaluating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9qbCmayNfLjF",
      "metadata": {
        "id": "9qbCmayNfLjF"
      },
      "source": [
        "- Test the Model on New Data: Evaluate the performance of the model after training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1SbweacKfRuI",
      "metadata": {
        "id": "1SbweacKfRuI"
      },
      "source": [
        "##7. Integrating OpenAI API (for advanced usage)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GjDbb-eVfW-V",
      "metadata": {
        "id": "GjDbb-eVfW-V"
      },
      "source": [
        "Since you have already been taught about the OpenAI API, you could integrate it with PyTorch for applications like using pre-trained models or generating text based on water-related predictions.\n",
        "\n",
        "Example integration snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VZtAQCUkfdz1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZtAQCUkfdz1",
        "outputId": "07c787fd-8e3b-45e0-c607-3e2190253283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reducing data size to 56 data points.\n",
            "An error occurred: Error code: 400 - {'error': {'message': \"This model's maximum context length is 4097 tokens, however you requested 5453 tokens (5403 in your prompt; 50 for the completion). Please reduce your prompt; or completion length.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "import tiktoken\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def generate_prediction(input_data):\n",
        "    client = openai.OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "    # Get the encoding for the model\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo-instruct\")\n",
        "    max_tokens = 4097  # Maximum context length for gpt-3.5-turbo-instruct\n",
        "    completion_tokens = 50 # Tokens reserved for the completion\n",
        "    available_tokens = max_tokens - completion_tokens\n",
        "\n",
        "    # Estimate token count per data point\n",
        "    if input_data.shape[0] > 0:\n",
        "        # Take the string representation of the first data point\n",
        "        sample_data_string = str(input_data[0])\n",
        "        tokens_per_data_point = len(encoding.encode(sample_data_string))\n",
        "        # Add some buffer for formatting (commas, brackets, etc.)\n",
        "        estimated_tokens_per_data_point = tokens_per_data_point + 5\n",
        "    else:\n",
        "        return \"Input data is empty.\"\n",
        "\n",
        "    # Calculate how many data points can fit\n",
        "    # Reserve some tokens for the prompt text itself\n",
        "    prompt_text_tokens = len(encoding.encode(\"Given the data , predict the water quality levels.\"))\n",
        "    data_tokens_capacity = available_tokens - prompt_text_tokens\n",
        "\n",
        "    if estimated_tokens_per_data_point > 0:\n",
        "        num_data_points_to_include = data_tokens_capacity // estimated_tokens_per_data_point\n",
        "    else:\n",
        "        num_data_points_to_include = 0\n",
        "\n",
        "\n",
        "    # Select data points to include\n",
        "    if num_data_points_to_include > 0 and input_data.shape[0] > num_data_points_to_include:\n",
        "        # Randomly sample the calculated number of data points\n",
        "        indices_to_include = random.sample(range(input_data.shape[0]), min(input_data.shape[0], num_data_points_to_include))\n",
        "        selected_data = input_data[indices_to_include]\n",
        "        print(f\"Reducing data size to {min(input_data.shape[0], num_data_points_to_include)} data points.\")\n",
        "    else:\n",
        "        selected_data = input_data # Include all data if it fits or is empty\n",
        "        if input_data.shape[0] > 0:\n",
        "            print(\"Including all data points.\")\n",
        "        else:\n",
        "            print(\"No data points to include.\")\n",
        "\n",
        "\n",
        "    data_string = str(selected_data)\n",
        "    prompt=f\"Given the data {data_string}, predict the water quality levels.\"\n",
        "\n",
        "\n",
        "    try:\n",
        "        response = client.completions.create(\n",
        "            model=\"gpt-3.5-turbo-instruct\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=completion_tokens\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "# Example usage with the data tensor from the previous cell\n",
        "print(generate_prediction(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BoNlkFnsnlzY",
      "metadata": {
        "id": "BoNlkFnsnlzY"
      },
      "source": [
        "#üõ†Ô∏è Creating a pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "liHCEXB1oaxa",
      "metadata": {
        "id": "liHCEXB1oaxa"
      },
      "source": [
        "##Conceptualizing the Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0nyArixfoekZ",
      "metadata": {
        "id": "0nyArixfoekZ"
      },
      "source": [
        "1. Problem Understanding\n",
        "To begin, let‚Äôs first define a scenario where we could use NNs, RAG, and LLMs together. Consider a question-answering (QA) system that needs to:\n",
        "\n",
        " - Retrieve relevant documents from a knowledge base (RAG component).\n",
        "\n",
        " - Process the text and use a neural network (NN) to better understand it (NN component).\n",
        "\n",
        " - Generate a detailed response with a language model, enriched by the retrieved documents (LLM component).\n",
        "\n",
        "2. Components of the Pipeline\n",
        "Neural Network (NN): A neural network could be used for text preprocessing, such as extracting features or understanding the semantics of the input query or text.\n",
        "\n",
        " - Retrieval-Augmented Generation (RAG): This module retrieves relevant documents from an external knowledge base (e.g., a database of articles or papers) based on the query.\n",
        "\n",
        " - Large Language Model (LLM): The LLM generates a response based on both the query and the retrieved documents, leveraging its pretrained knowledge to produce detailed, context-rich answers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lmnv438tHuek",
      "metadata": {
        "id": "lmnv438tHuek"
      },
      "source": [
        "## Modeling the Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TIoRN7BUHx5U",
      "metadata": {
        "id": "TIoRN7BUHx5U"
      },
      "source": [
        "Step 1: Define Your Task\n",
        "For this tutorial, let‚Äôs assume we are building a QA system that retrieves articles from a document database (using RAG) and generates responses to questions using a large language model (like GPT).\n",
        "\n",
        "We‚Äôll define the pipeline in three stages:\n",
        "\n",
        " 1. Document Retrieval: Fetch documents from a knowledge base.\n",
        "\n",
        " 2. Document Understanding: Process the documents using a neural network to extract features and understand them.\n",
        "\n",
        " 3. Answer Generation: Use an LLM to generate a final answer, augmented by the retrieved documents.\n",
        "\n",
        "\n",
        "Step 2: Design the Pipeline Workflow\n",
        "Input: User query or question.\n",
        "\n",
        "- Stage 1 (RAG - Retrieval):\n",
        "\n",
        " - Use a retrieval system (such as Elasticsearch or FAISS) to find relevant documents.\n",
        "\n",
        "- Stage 2 (NN - Document Understanding):\n",
        "\n",
        " - Preprocess the retrieved documents (e.g., sentence segmentation, embedding generation) with a neural network.\n",
        "\n",
        "- Stage 3 (LLM - Answer Generation):\n",
        "\n",
        " - Use the LLM to generate an answer by providing the user query and the processed documents as context.\n",
        "\n",
        "\n",
        "Part 3: Implementing the Pipeline\n",
        "\n",
        "- Step 1: Setup Dependencies\n",
        "You‚Äôll need a few libraries for this task:\n",
        "\n",
        " - Hugging Face's Transformers for the LLM (like GPT-3, GPT-4, or BERT for document understanding).\n",
        "\n",
        " - FAISS or Elasticsearch for the retrieval mechanism.\n",
        "\n",
        " - PyTorch or TensorFlow for building the NN components.\n",
        "\n",
        " Install these dependencies first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cJIg1hgRIxnc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJIg1hgRIxnc",
        "outputId": "7fe73681-fd8a-47db-a894-b76e705b2c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers faiss-cpu torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p9gYE_a5LJvr",
      "metadata": {
        "id": "p9gYE_a5LJvr"
      },
      "source": [
        "- Step 2: Define your data\n",
        " - Example document: [Water_and_Flooding_Services](https://docs.google.com/document/d/1IX2bKinZLEZP_nK1jdAGLShDG8X1Chye/edit?usp=sharing&ouid=118264855319059337623&rtpof=true&sd=true)\n",
        " - Convert data to json/make it machine readable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "EIx1L6NZM6m2",
      "metadata": {
        "id": "EIx1L6NZM6m2"
      },
      "outputs": [],
      "source": [
        "documents=[\n",
        "  {\n",
        "    \"title\": \"Water and Flooding Services\",\n",
        "    \"content\": \"Flooding is one of the most common and destructive natural disasters, impacting communities worldwide. Understanding and addressing flooding is essential for safeguarding lives, infrastructure, and the environment. Various services and technologies are designed to monitor, predict, and manage floods effectively. These services can range from monitoring flood risks to responding to flood events.\"\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Key Aspects of Water and Flooding Services\",\n",
        "    \"sections\": [\n",
        "      {\n",
        "        \"heading\": \"1. Flood Prediction and Forecasting\",\n",
        "        \"content\": [\n",
        "          \"Hydrological Models: These models simulate the flow of water in rivers, streams, and catchments to predict the likelihood of floods. They rely on weather data, historical rainfall, and water level measurements.\",\n",
        "          \"Weather Forecasting: Meteorological agencies use sophisticated models to forecast rainfall, which is a major trigger for flooding. Forecasting can provide early warnings about impending storms and floods.\"\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"heading\": \"2. Flood Monitoring\",\n",
        "        \"content\": [\n",
        "          \"River Gauging Stations: These stations monitor water levels in rivers and streams. Changes in water levels can indicate potential flooding.\",\n",
        "          \"Satellite Monitoring: Remote sensing technologies, including satellites, can provide real-time data on water levels, rainfall, and snowmelt, allowing for better monitoring of large areas.\"\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"heading\": \"3. Flood Risk Assessment\",\n",
        "        \"content\": [\n",
        "          \"Flood Mapping: Flood maps are created based on historical data and simulations to determine areas that are at risk of flooding. These maps help in urban planning and building regulations, ensuring that structures are built in safe locations.\",\n",
        "          \"Risk Models: Flood risk models integrate data on topography, hydrology, and infrastructure to assess flood risks in different regions.\"\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"heading\": \"4. Flood Mitigation and Management\",\n",
        "        \"content\": [\n",
        "          \"Flood Defenses: Infrastructure such as levees, dams, reservoirs, and flood barriers are constructed to protect vulnerable areas from floods.\",\n",
        "          \"Natural Solutions: Restoring wetlands, forests, and other natural landscapes can help absorb excess water and reduce the impact of flooding.\",\n",
        "          \"Floodplain Zoning: Floodplain zoning regulations are used to restrict construction in high-risk areas and encourage flood-resistant designs in at-risk locations.\"\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"heading\": \"5. Flood Response and Recovery\",\n",
        "        \"content\": [\n",
        "          \"Flood Warning Systems: Automated flood warning systems alert communities about potential floods through sirens, text messages, or apps. Early warnings help people evacuate and protect assets in time.\",\n",
        "          \"Emergency Services: In case of flooding, emergency services, such as fire and rescue teams, are deployed to help evacuate people, provide medical assistance, and rescue stranded individuals.\",\n",
        "          \"Post-Flood Recovery: Once a flood event subsides, recovery services help repair damaged infrastructure, provide financial support, and assist in long-term rebuilding efforts.\"\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Technology in Flood and Water Management\",\n",
        "    \"sections\": [\n",
        "      {\n",
        "        \"heading\": \"1. Artificial Intelligence (AI)\",\n",
        "        \"content\": \"AI can be used to enhance flood prediction models by analyzing historical data, weather patterns, and real-time environmental data to forecast floods more accurately.\"\n",
        "      },\n",
        "      {\n",
        "        \"heading\": \"2. Internet of Things (IoT)\",\n",
        "        \"content\": \"IoT sensors can be deployed in rivers, dams, and other flood-prone areas to collect real-time data on water levels, rainfall, and environmental conditions. This data can be analyzed for early flood detection.\"\n",
        "      },\n",
        "      {\n",
        "        \"heading\": \"3. Geospatial Technologies\",\n",
        "        \"content\": \"Geographic Information System (GIS) and remote sensing technologies enable the creation of detailed flood maps, providing insights into flood risks and potential impacts on communities.\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Applications of Water and Flooding Services\",\n",
        "    \"sections\": [\n",
        "      {\n",
        "        \"heading\": \"1. Disaster Risk Reduction\",\n",
        "        \"content\": \"By predicting floods and providing early warnings, communities can reduce the damage caused by floods and take preventive measures.\"\n",
        "      },\n",
        "      {\n",
        "        \"heading\": \"2. Urban Planning\",\n",
        "        \"content\": \"Flood risk assessments and floodplain zoning play an essential role in the design of cities and towns, ensuring buildings and infrastructure are placed in safe areas.\"\n",
        "      },\n",
        "      {\n",
        "        \"heading\": \"3. Agriculture and Water Resources\",\n",
        "        \"content\": \"Flood management is crucial for agriculture, as floods can destroy crops and disrupt water resources. Early warnings can help farmers protect their crops and manage irrigation systems more effectively.\"\n",
        "      },\n",
        "      {\n",
        "        \"heading\": \"4. Insurance\",\n",
        "        \"content\": \"Flood risk mapping helps insurance companies assess the risk of floods in different regions, allowing them to set premiums based on the likelihood of flood damage.\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Flooding and Water Services for Communities\",\n",
        "    \"sections\": [\n",
        "      {\n",
        "        \"heading\": \"1. Flood Insurance\",\n",
        "        \"content\": \"Coverage that helps homeowners and businesses recover financially after a flood. Flood insurance policies are designed to cover damages not typically included in regular homeowners insurance.\"\n",
        "      },\n",
        "      {\n",
        "        \"heading\": \"2. Community Flood Preparedness Programs\",\n",
        "        \"content\": \"Many governments offer programs to educate communities about flood risks, evacuation plans, and emergency preparedness.\"\n",
        "      },\n",
        "      {\n",
        "        \"heading\": \"3. Flood Response Services\",\n",
        "        \"content\": \"Local authorities often have dedicated flood response teams that coordinate evacuation plans, set up temporary shelters, and provide resources to affected individuals during and after flooding events.\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Conclusion\",\n",
        "    \"content\": \"Flooding is a complex challenge that requires a combination of predictive modeling, infrastructure planning, real-time monitoring, and community preparedness. By leveraging modern technologies, such as AI, IoT, and satellite data, communities can improve their flood resilience and minimize the impact of floods on their populations. Effective water and flooding services are crucial for managing and mitigating the risks associated with floods, ensuring both human safety and environmental protection.\"\n",
        "  }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rO_EybfsIztT",
      "metadata": {
        "id": "rO_EybfsIztT"
      },
      "source": [
        "- Step 3: Implement the RAG Component (Document Retrieval)\n",
        "For the retrieval step, we'll use FAISS (Facebook AI Similarity Search) for document retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "nSGOhpbbI14o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSGOhpbbI14o",
        "outputId": "8998dcea-f637-43f2-cd4a-45df5a762782"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'title': 'Conclusion', 'content': 'Flooding is a complex challenge that requires a combination of predictive modeling, infrastructure planning, real-time monitoring, and community preparedness. By leveraging modern technologies, such as AI, IoT, and satellite data, communities can improve their flood resilience and minimize the impact of floods on their populations. Effective water and flooding services are crucial for managing and mitigating the risks associated with floods, ensuring both human safety and environmental protection.'}, {'title': 'Technology in Flood and Water Management', 'sections': [{'heading': '1. Artificial Intelligence (AI)', 'content': 'AI can be used to enhance flood prediction models by analyzing historical data, weather patterns, and real-time environmental data to forecast floods more accurately.'}, {'heading': '2. Internet of Things (IoT)', 'content': 'IoT sensors can be deployed in rivers, dams, and other flood-prone areas to collect real-time data on water levels, rainfall, and environmental conditions. This data can be analyzed for early flood detection.'}, {'heading': '3. Geospatial Technologies', 'content': 'Geographic Information System (GIS) and remote sensing technologies enable the creation of detailed flood maps, providing insights into flood risks and potential impacts on communities.'}]}, {'title': 'Key Aspects of Water and Flooding Services', 'sections': [{'heading': '1. Flood Prediction and Forecasting', 'content': ['Hydrological Models: These models simulate the flow of water in rivers, streams, and catchments to predict the likelihood of floods. They rely on weather data, historical rainfall, and water level measurements.', 'Weather Forecasting: Meteorological agencies use sophisticated models to forecast rainfall, which is a major trigger for flooding. Forecasting can provide early warnings about impending storms and floods.']}, {'heading': '2. Flood Monitoring', 'content': ['River Gauging Stations: These stations monitor water levels in rivers and streams. Changes in water levels can indicate potential flooding.', 'Satellite Monitoring: Remote sensing technologies, including satellites, can provide real-time data on water levels, rainfall, and snowmelt, allowing for better monitoring of large areas.']}, {'heading': '3. Flood Risk Assessment', 'content': ['Flood Mapping: Flood maps are created based on historical data and simulations to determine areas that are at risk of flooding. These maps help in urban planning and building regulations, ensuring that structures are built in safe locations.', 'Risk Models: Flood risk models integrate data on topography, hydrology, and infrastructure to assess flood risks in different regions.']}, {'heading': '4. Flood Mitigation and Management', 'content': ['Flood Defenses: Infrastructure such as levees, dams, reservoirs, and flood barriers are constructed to protect vulnerable areas from floods.', 'Natural Solutions: Restoring wetlands, forests, and other natural landscapes can help absorb excess water and reduce the impact of flooding.', 'Floodplain Zoning: Floodplain zoning regulations are used to restrict construction in high-risk areas and encourage flood-resistant designs in at-risk locations.']}, {'heading': '5. Flood Response and Recovery', 'content': ['Flood Warning Systems: Automated flood warning systems alert communities about potential floods through sirens, text messages, or apps. Early warnings help people evacuate and protect assets in time.', 'Emergency Services: In case of flooding, emergency services, such as fire and rescue teams, are deployed to help evacuate people, provide medical assistance, and rescue stranded individuals.', 'Post-Flood Recovery: Once a flood event subsides, recovery services help repair damaged infrastructure, provide financial support, and assist in long-term rebuilding efforts.']}]}]\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Example: FAISS index setup for document retrieval\n",
        "dimension = 768  # Size of the embedding (depends on your model, e.g., BERT)\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 distance index for FAISS\n",
        "\n",
        "# Example documents (replace with actual embeddings of your documents)\n",
        "document_embeddings = np.random.rand(len(documents), dimension).astype('float32')\n",
        "\n",
        "# Add document embeddings to FAISS index\n",
        "index.add(document_embeddings)\n",
        "\n",
        "def retrieve_documents(query_embedding, top_k=3):\n",
        "    # Search for the top_k most similar documents\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    return [documents[i] for i in indices[0]]\n",
        "\n",
        "# Example: Query embedding (replace with actual model embeddings)\n",
        "query_embedding = np.random.rand(1, dimension).astype('float32')\n",
        "\n",
        "# Retrieve top 3 similar documents\n",
        "retrieved_docs = retrieve_documents(query_embedding)\n",
        "print(retrieved_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EY3Yz4meI38q",
      "metadata": {
        "id": "EY3Yz4meI38q"
      },
      "source": [
        "Here, FAISS helps to quickly search and retrieve the most relevant documents based on a query embedding.\n",
        "\n",
        "- Step 4: Implement the NN Component (Document Understanding)\n",
        "Now, let's process the retrieved documents using a neural network model. For this, we'll use BERT to embed the documents and query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "nhL2Q1B_I6SJ",
      "metadata": {
        "id": "nhL2Q1B_I6SJ"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Initialize BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def encode_document(doc):\n",
        "    # Extract text content from the document dictionary\n",
        "    if \"content\" in doc:\n",
        "        text = doc[\"content\"]\n",
        "    elif \"sections\" in doc:\n",
        "        # Concatenate content from all sections if available\n",
        "        text = \" \".join([section[\"content\"] for section in doc[\"sections\"] if isinstance(section[\"content\"], str)])\n",
        "    else:\n",
        "        text = \"\" # Handle cases with no content or sections\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "    outputs = bert_model(**inputs)\n",
        "    # Use mean pooling for sentence embedding, handle potential empty outputs\n",
        "    if outputs.last_hidden_state.shape[1] > 0:\n",
        "        return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    else:\n",
        "        return np.zeros((1, bert_model.config.hidden_size), dtype=np.float32)\n",
        "\n",
        "\n",
        "# Example: Encoding the retrieved documents\n",
        "encoded_docs = [encode_document(doc) for doc in retrieved_docs]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I_-8DYHjI8sC",
      "metadata": {
        "id": "I_-8DYHjI8sC"
      },
      "source": [
        "In this step, we use BERT to encode the documents into embeddings. You can use any other pre-trained model based on your needs.\n",
        "\n",
        "- Step 5: Implement the LLM Component (Answer Generation)\n",
        "Finally, let‚Äôs use an LLM like GPT-3 or GPT-4 to generate an answer based on the query and the retrieved documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "TbvkJ6t2JFSj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbvkJ6t2JFSj",
        "outputId": "c597cc13-6a73-497f-eda7-0c723fe58edc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flooding is a complex challenge that requires a combination of predictive modeling, infrastructure planning, real-time monitoring, and community preparedness. By leveraging modern technologies, such as AI, IoT, and satellite data, communities can improve their flood resilience and minimize the impact of floods on their populations. Effective water and flooding services are crucial for managing and mitigating the risks associated with floods, ensuring both human safety and environmental protection. AI can be used to enhance flood prediction models by analyzing historical data, weather patterns, and real-time environmental data to forecast floods more accurately. IoT sensors can be deployed in rivers, dams, and other flood-prone areas to collect real-time data on water levels, rainfall, and environmental conditions. This data can be analyzed for early flood detection. Geographic Information System (GIS) and remote sensing technologies enable the creation of detailed flood maps, providing insights into flood risks and potential impacts on communities.  What is the impact of heavy rainfall on flood risk? The impact of heavy rainfall on flood risk is a complex issue. The most common impacts are:\n",
            "\n",
            "‚Ä¢ Floods that are more than 10 feet high\n",
            "\n",
            "‚Ä¢ Floods that are more than 10 feet high in the center of a flood zone\n",
            "\n",
            "‚Ä¢ Floods that are more than 10 feet high in the center of a flood zone in the center of a flood zone\n",
            "\n",
            "‚Ä¢ Floods that are more than 10 feet high in the center of a flood zone in the center of a flood zone\n",
            "\n",
            "‚Ä¢ Floods that are more than 10 feet high in the center of a flood zone in the center of a flood zone\n",
            "\n",
            "‚Ä¢ Floods that are more than 10 feet high in the center of a flood zone in the center of a flood zone\n",
            "\n",
            "‚Ä¢ Floods that are more than 10 feet high in the center of a flood zone in the center of a flood zone\n",
            "\n",
            "‚Ä¢ Floods that are more than 10 feet high in the center of a flood zone in\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "# Initialize GPT model and tokenizer (or use GPT-3 via OpenAI API)\n",
        "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Set pad token ID if it's not already set\n",
        "if gpt_tokenizer.pad_token is None:\n",
        "    gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
        "\n",
        "\n",
        "def generate_answer(query, retrieved_docs):\n",
        "    # Extract text content from each document and join them\n",
        "    document_texts = []\n",
        "    for doc in retrieved_docs:\n",
        "        if \"content\" in doc:\n",
        "            document_texts.append(doc[\"content\"])\n",
        "        elif \"sections\" in doc:\n",
        "            # Concatenate content from all sections if available\n",
        "            section_content = \" \".join([section[\"content\"] for section in doc[\"sections\"] if isinstance(section[\"content\"], str)])\n",
        "            document_texts.append(section_content)\n",
        "\n",
        "    context = \" \".join(document_texts) + \" \" + query  # Combine query and retrieved docs\n",
        "\n",
        "    # Encode the context and return attention mask\n",
        "    inputs = gpt_tokenizer.encode_plus(\n",
        "        context,\n",
        "        return_tensors='pt',\n",
        "        padding=True,  # Enable padding\n",
        "        truncation=True # Enable truncation if context is too long\n",
        "    )\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    outputs = gpt_model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask, # Pass attention mask\n",
        "        max_new_tokens=200, # Use max_new_tokens instead of max_length\n",
        "        num_return_sequences=1,\n",
        "        pad_token_id=gpt_tokenizer.pad_token_id # Pass pad token id\n",
        "    )\n",
        "    return gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Example: Generate answer based on the query and retrieved documents\n",
        "query = \"What is the impact of heavy rainfall on flood risk?\"\n",
        "answer = generate_answer(query, retrieved_docs)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ytxb5dsXJHMt",
      "metadata": {
        "id": "ytxb5dsXJHMt"
      },
      "source": [
        "Here, GPT-2 (or GPT-3 via API) generates the final answer, using both the query and the retrieved documents as context.\n",
        "\n",
        "Part 4: Putting It All Together\n",
        "Now, let‚Äôs combine all components into a single pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "9ablA8wqJVZT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ablA8wqJVZT",
        "outputId": "502a0cfc-aaab-42b1-c78c-153567cbcd6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI can be used to enhance flood prediction models by analyzing historical data, weather patterns, and real-time environmental data to forecast floods more accurately. IoT sensors can be deployed in rivers, dams, and other flood-prone areas to collect real-time data on water levels, rainfall, and environmental conditions. This data can be analyzed for early flood detection. Geographic Information System (GIS) and remote sensing technologies enable the creation of detailed flood maps, providing insights into flood risks and potential impacts on communities. By predicting floods and providing early warnings, communities can reduce the damage caused by floods and take preventive measures. Flood risk assessments and floodplain zoning play an essential role in the design of cities and towns, ensuring buildings and infrastructure are placed in safe areas. Flood management is crucial for agriculture, as floods can destroy crops and disrupt water resources. Early warnings can help farmers protect their crops and manage irrigation systems more effectively. Flood risk mapping helps insurance companies assess the risk of floods in different regions, allowing them to set premiums based on the likelihood of flood damage. Flooding is a complex challenge that requires a combination of predictive modeling, infrastructure planning, real-time monitoring, and community preparedness. By leveraging modern technologies, such as AI, IoT, and satellite data, communities can improve their flood resilience and minimize the impact of floods on their populations. Effective water and flooding services are crucial for managing and mitigating the risks associated with floods, ensuring both human safety and environmental protection. What measures can prevent flooding in urban areas? Flood risk assessment and floodplain zoning are critical for planning and managing flood risk. Flood risk assessment and floodplain zoning are critical for planning and managing flood risk. Flood risk assessment and floodplain zoning are critical for planning and managing flood risk. Flood risk assessment and floodplain zoning are critical for planning and managing flood risk. Flood risk assessment and floodplain zoning are critical for planning and managing flood risk. Flood risk assessment and floodplain zoning are critical for planning and managing flood risk. Flood risk assessment and floodplain zoning are critical for planning and managing flood risk. Flood risk assessment and floodplain zoning are critical for planning and managing flood risk. Flood risk assessment and floodplain zoning are critical for planning and managing flood risk. Flood risk assessment and floodplain zoning are critical for planning and managing flood risk. Flood risk assessment and floodplain zoning are critical for planning and managing flood risk. Flood risk assessment and floodplain zoning are critical for planning and managing flood risk. Flood risk assessment and floodplain zoning are\n"
          ]
        }
      ],
      "source": [
        "def qa_pipeline(query):\n",
        "    # Step 1: Retrieve documents (RAG)\n",
        "    # Encode the query using the BERT model and tokenizer\n",
        "    query_inputs = tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
        "    query_outputs = bert_model(**query_inputs)\n",
        "    query_embedding = query_outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "\n",
        "    retrieved_docs = retrieve_documents(query_embedding)\n",
        "\n",
        "    # Step 2: Generate answer (LLM)\n",
        "    answer = generate_answer(query, retrieved_docs)\n",
        "    return answer\n",
        "\n",
        "# Example: Running the pipeline\n",
        "query = \"What measures can prevent flooding in urban areas?\"\n",
        "final_answer = qa_pipeline(query)\n",
        "print(final_answer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
